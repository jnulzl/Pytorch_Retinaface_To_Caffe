name:"deploy"
layer{
		name:"data"
		type:"Input"
		top:"data"
		input_param{
			shape:{
				dim:1
				dim:3
				dim:512
				dim:512
			}
		}
}
####################body-stage1-0####################
layer{
		name:"Conv2d_0"
		type:"Convolution"
		bottom:"data"
		top:"Conv2d_0"
		convolution_param{
			num_output:8
			group:1
			kernel_size:3
			stride:2
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_1_BN"
		type:"BatchNorm"
		bottom:"Conv2d_0"
		top:"Conv2d_0"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_1_Scale"
		type:"Scale"
		bottom:"Conv2d_0"
		top:"Conv2d_0"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_2"
		type:"ReLU"
		bottom:"Conv2d_0"
		top:"Conv2d_0"
		relu_param{
			negative_slope:0.1
		}
}
####################body-stage1-1####################
layer{
		name:"Conv2d_3"
		type:"Convolution"
		bottom:"Conv2d_0"
		top:"Conv2d_3"
		convolution_param{
			num_output:8
			group:8
			kernel_size:3
			stride:1
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_4_BN"
		type:"BatchNorm"
		bottom:"Conv2d_3"
		top:"Conv2d_3"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_4_Scale"
		type:"Scale"
		bottom:"Conv2d_3"
		top:"Conv2d_3"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_5"
		type:"ReLU"
		bottom:"Conv2d_3"
		top:"Conv2d_3"
		relu_param{
			negative_slope:0.1
		}
}
layer{
		name:"Conv2d_6"
		type:"Convolution"
		bottom:"Conv2d_3"
		top:"Conv2d_6"
		convolution_param{
			num_output:16
			group:1
			kernel_size:1
			stride:1
			pad:0
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_7_BN"
		type:"BatchNorm"
		bottom:"Conv2d_6"
		top:"Conv2d_6"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_7_Scale"
		type:"Scale"
		bottom:"Conv2d_6"
		top:"Conv2d_6"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_8"
		type:"ReLU"
		bottom:"Conv2d_6"
		top:"Conv2d_6"
		relu_param{
			negative_slope:0.1
		}
}
####################body-stage1-2####################
layer{
		name:"Conv2d_9"
		type:"Convolution"
		bottom:"Conv2d_6"
		top:"Conv2d_9"
		convolution_param{
			num_output:16
			group:16
			kernel_size:3
			stride:2
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_10_BN"
		type:"BatchNorm"
		bottom:"Conv2d_9"
		top:"Conv2d_9"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_10_Scale"
		type:"Scale"
		bottom:"Conv2d_9"
		top:"Conv2d_9"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_11"
		type:"ReLU"
		bottom:"Conv2d_9"
		top:"Conv2d_9"
		relu_param{
			negative_slope:0.1
		}
}
layer{
		name:"Conv2d_12"
		type:"Convolution"
		bottom:"Conv2d_9"
		top:"Conv2d_12"
		convolution_param{
			num_output:32
			group:1
			kernel_size:1
			stride:1
			pad:0
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_13_BN"
		type:"BatchNorm"
		bottom:"Conv2d_12"
		top:"Conv2d_12"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_13_Scale"
		type:"Scale"
		bottom:"Conv2d_12"
		top:"Conv2d_12"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_14"
		type:"ReLU"
		bottom:"Conv2d_12"
		top:"Conv2d_12"
		relu_param{
			negative_slope:0.1
		}
}
####################body-stage1-3####################
layer{
		name:"Conv2d_15"
		type:"Convolution"
		bottom:"Conv2d_12"
		top:"Conv2d_15"
		convolution_param{
			num_output:32
			group:32
			kernel_size:3
			stride:1
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_16_BN"
		type:"BatchNorm"
		bottom:"Conv2d_15"
		top:"Conv2d_15"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_16_Scale"
		type:"Scale"
		bottom:"Conv2d_15"
		top:"Conv2d_15"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_17"
		type:"ReLU"
		bottom:"Conv2d_15"
		top:"Conv2d_15"
		relu_param{
			negative_slope:0.1
		}
}
layer{
		name:"Conv2d_18"
		type:"Convolution"
		bottom:"Conv2d_15"
		top:"Conv2d_18"
		convolution_param{
			num_output:32
			group:1
			kernel_size:1
			stride:1
			pad:0
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_19_BN"
		type:"BatchNorm"
		bottom:"Conv2d_18"
		top:"Conv2d_18"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_19_Scale"
		type:"Scale"
		bottom:"Conv2d_18"
		top:"Conv2d_18"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_20"
		type:"ReLU"
		bottom:"Conv2d_18"
		top:"Conv2d_18"
		relu_param{
			negative_slope:0.1
		}
}
####################body-stage1-4####################
layer{
		name:"Conv2d_21"
		type:"Convolution"
		bottom:"Conv2d_18"
		top:"Conv2d_21"
		convolution_param{
			num_output:32
			group:32
			kernel_size:3
			stride:2
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_22_BN"
		type:"BatchNorm"
		bottom:"Conv2d_21"
		top:"Conv2d_21"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_22_Scale"
		type:"Scale"
		bottom:"Conv2d_21"
		top:"Conv2d_21"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_23"
		type:"ReLU"
		bottom:"Conv2d_21"
		top:"Conv2d_21"
		relu_param{
			negative_slope:0.1
		}
}
layer{
		name:"Conv2d_24"
		type:"Convolution"
		bottom:"Conv2d_21"
		top:"Conv2d_24"
		convolution_param{
			num_output:64
			group:1
			kernel_size:1
			stride:1
			pad:0
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_25_BN"
		type:"BatchNorm"
		bottom:"Conv2d_24"
		top:"Conv2d_24"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_25_Scale"
		type:"Scale"
		bottom:"Conv2d_24"
		top:"Conv2d_24"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_26"
		type:"ReLU"
		bottom:"Conv2d_24"
		top:"Conv2d_24"
		relu_param{
			negative_slope:0.1
		}
}
####################body-stage1-5####################
layer{
		name:"Conv2d_27"
		type:"Convolution"
		bottom:"Conv2d_24"
		top:"Conv2d_27"
		convolution_param{
			num_output:64
			group:64
			kernel_size:3
			stride:1
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_28_BN"
		type:"BatchNorm"
		bottom:"Conv2d_27"
		top:"Conv2d_27"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_28_Scale"
		type:"Scale"
		bottom:"Conv2d_27"
		top:"Conv2d_27"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_29"
		type:"ReLU"
		bottom:"Conv2d_27"
		top:"Conv2d_27"
		relu_param{
			negative_slope:0.1
		}
}
layer{
		name:"Conv2d_30"
		type:"Convolution"
		bottom:"Conv2d_27"
		top:"Conv2d_30"
		convolution_param{
			num_output:64
			group:1
			kernel_size:1
			stride:1
			pad:0
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_31_BN"
		type:"BatchNorm"
		bottom:"Conv2d_30"
		top:"Conv2d_30"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_31_Scale"
		type:"Scale"
		bottom:"Conv2d_30"
		top:"Conv2d_30"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_32"
		type:"ReLU"
		bottom:"Conv2d_30"
		top:"Conv2d_30"
		relu_param{
			negative_slope:0.1
		}
}
####################body-stage2-0####################
layer{
		name:"Conv2d_33"
		type:"Convolution"
		bottom:"Conv2d_30"
		top:"Conv2d_33"
		convolution_param{
			num_output:64
			group:64
			kernel_size:3
			stride:2
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_34_BN"
		type:"BatchNorm"
		bottom:"Conv2d_33"
		top:"Conv2d_33"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_34_Scale"
		type:"Scale"
		bottom:"Conv2d_33"
		top:"Conv2d_33"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_35"
		type:"ReLU"
		bottom:"Conv2d_33"
		top:"Conv2d_33"
		relu_param{
			negative_slope:0.1
		}
}
layer{
		name:"Conv2d_36"
		type:"Convolution"
		bottom:"Conv2d_33"
		top:"Conv2d_36"
		convolution_param{
			num_output:128
			group:1
			kernel_size:1
			stride:1
			pad:0
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_37_BN"
		type:"BatchNorm"
		bottom:"Conv2d_36"
		top:"Conv2d_36"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_37_Scale"
		type:"Scale"
		bottom:"Conv2d_36"
		top:"Conv2d_36"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_38"
		type:"ReLU"
		bottom:"Conv2d_36"
		top:"Conv2d_36"
		relu_param{
			negative_slope:0.1
		}
}
####################body-stage2-1####################
layer{
		name:"Conv2d_39"
		type:"Convolution"
		bottom:"Conv2d_36"
		top:"Conv2d_39"
		convolution_param{
			num_output:128
			group:128
			kernel_size:3
			stride:1
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_40_BN"
		type:"BatchNorm"
		bottom:"Conv2d_39"
		top:"Conv2d_39"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_40_Scale"
		type:"Scale"
		bottom:"Conv2d_39"
		top:"Conv2d_39"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_41"
		type:"ReLU"
		bottom:"Conv2d_39"
		top:"Conv2d_39"
		relu_param{
			negative_slope:0.1
		}
}
layer{
		name:"Conv2d_42"
		type:"Convolution"
		bottom:"Conv2d_39"
		top:"Conv2d_42"
		convolution_param{
			num_output:128
			group:1
			kernel_size:1
			stride:1
			pad:0
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_43_BN"
		type:"BatchNorm"
		bottom:"Conv2d_42"
		top:"Conv2d_42"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_43_Scale"
		type:"Scale"
		bottom:"Conv2d_42"
		top:"Conv2d_42"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_44"
		type:"ReLU"
		bottom:"Conv2d_42"
		top:"Conv2d_42"
		relu_param{
			negative_slope:0.1
		}
}
####################body-stage2-2####################
layer{
		name:"Conv2d_45"
		type:"Convolution"
		bottom:"Conv2d_42"
		top:"Conv2d_45"
		convolution_param{
			num_output:128
			group:128
			kernel_size:3
			stride:1
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_46_BN"
		type:"BatchNorm"
		bottom:"Conv2d_45"
		top:"Conv2d_45"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_46_Scale"
		type:"Scale"
		bottom:"Conv2d_45"
		top:"Conv2d_45"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_47"
		type:"ReLU"
		bottom:"Conv2d_45"
		top:"Conv2d_45"
		relu_param{
			negative_slope:0.1
		}
}
layer{
		name:"Conv2d_48"
		type:"Convolution"
		bottom:"Conv2d_45"
		top:"Conv2d_48"
		convolution_param{
			num_output:128
			group:1
			kernel_size:1
			stride:1
			pad:0
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_49_BN"
		type:"BatchNorm"
		bottom:"Conv2d_48"
		top:"Conv2d_48"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_49_Scale"
		type:"Scale"
		bottom:"Conv2d_48"
		top:"Conv2d_48"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_50"
		type:"ReLU"
		bottom:"Conv2d_48"
		top:"Conv2d_48"
		relu_param{
			negative_slope:0.1
		}
}
####################body-stage2-3####################
layer{
		name:"Conv2d_51"
		type:"Convolution"
		bottom:"Conv2d_48"
		top:"Conv2d_51"
		convolution_param{
			num_output:128
			group:128
			kernel_size:3
			stride:1
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_52_BN"
		type:"BatchNorm"
		bottom:"Conv2d_51"
		top:"Conv2d_51"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_52_Scale"
		type:"Scale"
		bottom:"Conv2d_51"
		top:"Conv2d_51"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_53"
		type:"ReLU"
		bottom:"Conv2d_51"
		top:"Conv2d_51"
		relu_param{
			negative_slope:0.1
		}
}
layer{
		name:"Conv2d_54"
		type:"Convolution"
		bottom:"Conv2d_51"
		top:"Conv2d_54"
		convolution_param{
			num_output:128
			group:1
			kernel_size:1
			stride:1
			pad:0
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_55_BN"
		type:"BatchNorm"
		bottom:"Conv2d_54"
		top:"Conv2d_54"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_55_Scale"
		type:"Scale"
		bottom:"Conv2d_54"
		top:"Conv2d_54"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_56"
		type:"ReLU"
		bottom:"Conv2d_54"
		top:"Conv2d_54"
		relu_param{
			negative_slope:0.1
		}
}
####################body-stage2-4####################
layer{
		name:"Conv2d_57"
		type:"Convolution"
		bottom:"Conv2d_54"
		top:"Conv2d_57"
		convolution_param{
			num_output:128
			group:128
			kernel_size:3
			stride:1
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_58_BN"
		type:"BatchNorm"
		bottom:"Conv2d_57"
		top:"Conv2d_57"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_58_Scale"
		type:"Scale"
		bottom:"Conv2d_57"
		top:"Conv2d_57"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_59"
		type:"ReLU"
		bottom:"Conv2d_57"
		top:"Conv2d_57"
		relu_param{
			negative_slope:0.1
		}
}
layer{
		name:"Conv2d_60"
		type:"Convolution"
		bottom:"Conv2d_57"
		top:"Conv2d_60"
		convolution_param{
			num_output:128
			group:1
			kernel_size:1
			stride:1
			pad:0
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_61_BN"
		type:"BatchNorm"
		bottom:"Conv2d_60"
		top:"Conv2d_60"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_61_Scale"
		type:"Scale"
		bottom:"Conv2d_60"
		top:"Conv2d_60"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_62"
		type:"ReLU"
		bottom:"Conv2d_60"
		top:"Conv2d_60"
		relu_param{
			negative_slope:0.1
		}
}
####################body-stage2-5####################
layer{
		name:"Conv2d_63"
		type:"Convolution"
		bottom:"Conv2d_60"
		top:"Conv2d_63"
		convolution_param{
			num_output:128
			group:128
			kernel_size:3
			stride:1
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_64_BN"
		type:"BatchNorm"
		bottom:"Conv2d_63"
		top:"Conv2d_63"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_64_Scale"
		type:"Scale"
		bottom:"Conv2d_63"
		top:"Conv2d_63"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_65"
		type:"ReLU"
		bottom:"Conv2d_63"
		top:"Conv2d_63"
		relu_param{
			negative_slope:0.1
		}
}
layer{
		name:"Conv2d_66"
		type:"Convolution"
		bottom:"Conv2d_63"
		top:"Conv2d_66"
		convolution_param{
			num_output:128
			group:1
			kernel_size:1
			stride:1
			pad:0
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_67_BN"
		type:"BatchNorm"
		bottom:"Conv2d_66"
		top:"Conv2d_66"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_67_Scale"
		type:"Scale"
		bottom:"Conv2d_66"
		top:"Conv2d_66"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_68"
		type:"ReLU"
		bottom:"Conv2d_66"
		top:"Conv2d_66"
		relu_param{
			negative_slope:0.1
		}
}
####################body-stage3-0####################
layer{
		name:"Conv2d_69"
		type:"Convolution"
		bottom:"Conv2d_66"
		top:"Conv2d_69"
		convolution_param{
			num_output:128
			group:128
			kernel_size:3
			stride:2
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_70_BN"
		type:"BatchNorm"
		bottom:"Conv2d_69"
		top:"Conv2d_69"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_70_Scale"
		type:"Scale"
		bottom:"Conv2d_69"
		top:"Conv2d_69"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_71"
		type:"ReLU"
		bottom:"Conv2d_69"
		top:"Conv2d_69"
		relu_param{
			negative_slope:0.1
		}
}
layer{
		name:"Conv2d_72"
		type:"Convolution"
		bottom:"Conv2d_69"
		top:"Conv2d_72"
		convolution_param{
			num_output:256
			group:1
			kernel_size:1
			stride:1
			pad:0
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_73_BN"
		type:"BatchNorm"
		bottom:"Conv2d_72"
		top:"Conv2d_72"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_73_Scale"
		type:"Scale"
		bottom:"Conv2d_72"
		top:"Conv2d_72"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_74"
		type:"ReLU"
		bottom:"Conv2d_72"
		top:"Conv2d_72"
		relu_param{
			negative_slope:0.1
		}
}
####################body-stage3-1####################
layer{
		name:"Conv2d_75"
		type:"Convolution"
		bottom:"Conv2d_72"
		top:"Conv2d_75"
		convolution_param{
			num_output:256
			group:256
			kernel_size:3
			stride:1
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_76_BN"
		type:"BatchNorm"
		bottom:"Conv2d_75"
		top:"Conv2d_75"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_76_Scale"
		type:"Scale"
		bottom:"Conv2d_75"
		top:"Conv2d_75"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_77"
		type:"ReLU"
		bottom:"Conv2d_75"
		top:"Conv2d_75"
		relu_param{
			negative_slope:0.1
		}
}
layer{
		name:"Conv2d_78"
		type:"Convolution"
		bottom:"Conv2d_75"
		top:"Conv2d_78"
		convolution_param{
			num_output:256
			group:1
			kernel_size:1
			stride:1
			pad:0
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_79_BN"
		type:"BatchNorm"
		bottom:"Conv2d_78"
		top:"Conv2d_78"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_79_Scale"
		type:"Scale"
		bottom:"Conv2d_78"
		top:"Conv2d_78"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_80"
		type:"ReLU"
		bottom:"Conv2d_78"
		top:"Conv2d_78"
		relu_param{
			negative_slope:0.1
		}
}

####################fpn-output1####################
layer{
		name:"Conv2d_81"
		type:"Convolution"
		bottom:"Conv2d_30"
		top:"Conv2d_81"
		convolution_param{
			num_output:64
			group:1
			kernel_size:1
			stride:1
			pad:0
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_82_BN"
		type:"BatchNorm"
		bottom:"Conv2d_81"
		top:"Conv2d_81"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_82_Scale"
		type:"Scale"
		bottom:"Conv2d_81"
		top:"Conv2d_81"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_83"
		type:"ReLU"
		bottom:"Conv2d_81"
		top:"Conv2d_81"
		relu_param{
			negative_slope:0.1
		}
}
####################fpn-output2####################
layer{
		name:"Conv2d_84"
		type:"Convolution"
		bottom:"Conv2d_66"
		top:"Conv2d_84"
		convolution_param{
			num_output:64
			group:1
			kernel_size:1
			stride:1
			pad:0
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_85_BN"
		type:"BatchNorm"
		bottom:"Conv2d_84"
		top:"Conv2d_84"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_85_Scale"
		type:"Scale"
		bottom:"Conv2d_84"
		top:"Conv2d_84"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_86"
		type:"ReLU"
		bottom:"Conv2d_84"
		top:"Conv2d_84"
		relu_param{
			negative_slope:0.1
		}
}
####################fpn-output3####################
layer{
		name:"Conv2d_87"
		type:"Convolution"
		bottom:"Conv2d_78"
		top:"Conv2d_87"
		convolution_param{
			num_output:64
			group:1
			kernel_size:1
			stride:1
			pad:0
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_88_BN"
		type:"BatchNorm"
		bottom:"Conv2d_87"
		top:"Conv2d_87"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_88_Scale"
		type:"Scale"
		bottom:"Conv2d_87"
		top:"Conv2d_87"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_89"
		type:"ReLU"
		bottom:"Conv2d_87"
		top:"Conv2d_87"
		relu_param{
			negative_slope:0.1
		}
}

#####################Upsample_nearest_1#####################
layer{
		name:"Upsample_nearest_1"
		type:"Upsample"
		bottom:"Conv2d_87"
		bottom:"Conv2d_84"
		top:"Upsample_nearest_1"
		upsample_param{
			mode: NEAREST
		}
}
layer 
{
		name:"Eltwise_1"
		type:"Eltwise"
		bottom:"Upsample_nearest_1"
		bottom:"Conv2d_84" 
		top:"Eltwise_1"
		eltwise_param {
			operation: SUM
		}
}

####################fpn-merge2####################
layer{
		name:"Conv2d_93"
		type:"Convolution"
		bottom:"Eltwise_1"
		top:"Conv2d_93"
		convolution_param{
			num_output:64
			group:1
			kernel_size:3
			stride:1
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_94_BN"
		type:"BatchNorm"
		bottom:"Conv2d_93"
		top:"Conv2d_93"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_94_Scale"
		type:"Scale"
		bottom:"Conv2d_93"
		top:"Conv2d_93"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_95"
		type:"ReLU"
		bottom:"Conv2d_93"
		top:"Conv2d_93"
		relu_param{
			negative_slope:0.1
		}
}

#####################Upsample_nearest_2#####################
layer{
		name:"Upsample_nearest_2"
		type:"Upsample"
		bottom:"Conv2d_93"
		bottom:"Conv2d_81" 
		top:"Upsample_nearest_2"
		upsample_param{
			mode: NEAREST
		}
}
layer 
{
		name:"Eltwise_2"
		type:"Eltwise"
		bottom:"Upsample_nearest_2"
		bottom:"Conv2d_81" 
		top:"Eltwise_2"
		eltwise_param {
			operation: SUM
		}
}


####################fpn-merge1####################
layer{
		name:"Conv2d_90"
		type:"Convolution"
		bottom:"Eltwise_2"
		top:"Conv2d_90"
		convolution_param{
			num_output:64
			group:1
			kernel_size:3
			stride:1
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_91_BN"
		type:"BatchNorm"
		bottom:"Conv2d_90"
		top:"Conv2d_90"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_91_Scale"
		type:"Scale"
		bottom:"Conv2d_90"
		top:"Conv2d_90"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_92"
		type:"ReLU"
		bottom:"Conv2d_90"
		top:"Conv2d_90"
		relu_param{
			negative_slope:0.1
		}
}



####################ssh1-conv3x3####################
layer{
		name:"Conv2d_96"
		type:"Convolution"
		bottom:"Conv2d_90"
		top:"Conv2d_96"
		convolution_param{
			num_output:32
			group:1
			kernel_size:3
			stride:1
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_97_BN"
		type:"BatchNorm"
		bottom:"Conv2d_96"
		top:"Conv2d_96"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_97_Scale"
		type:"Scale"
		bottom:"Conv2d_96"
		top:"Conv2d_96"
		scale_param{
			bias_term: true
		}
}
####################ssh1-conv5X5_1####################
layer{
		name:"Conv2d_98"
		type:"Convolution"
		bottom:"Conv2d_90"
		top:"Conv2d_98"
		convolution_param{
			num_output:16
			group:1
			kernel_size:3
			stride:1
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_99_BN"
		type:"BatchNorm"
		bottom:"Conv2d_98"
		top:"Conv2d_98"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_99_Scale"
		type:"Scale"
		bottom:"Conv2d_98"
		top:"Conv2d_98"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_100"
		type:"ReLU"
		bottom:"Conv2d_98"
		top:"Conv2d_98"
		relu_param{
			negative_slope:0.1
		}
}
####################ssh1-conv5X5_2####################
layer{
		name:"Conv2d_101"
		type:"Convolution"
		bottom:"Conv2d_98"
		top:"Conv2d_101"
		convolution_param{
			num_output:16
			group:1
			kernel_size:3
			stride:1
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_102_BN"
		type:"BatchNorm"
		bottom:"Conv2d_101"
		top:"Conv2d_101"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_102_Scale"
		type:"Scale"
		bottom:"Conv2d_101"
		top:"Conv2d_101"
		scale_param{
			bias_term: true
		}
}
####################ssh1-conv7X7_2####################
layer{
		name:"Conv2d_103"
		type:"Convolution"
		bottom:"Conv2d_98"
		top:"Conv2d_103"
		convolution_param{
			num_output:16
			group:1
			kernel_size:3
			stride:1
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_104_BN"
		type:"BatchNorm"
		bottom:"Conv2d_103"
		top:"Conv2d_103"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_104_Scale"
		type:"Scale"
		bottom:"Conv2d_103"
		top:"Conv2d_103"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_105"
		type:"ReLU"
		bottom:"Conv2d_103"
		top:"Conv2d_103"
		relu_param{
			negative_slope:0.1
		}
}
####################ssh1-conv7X7_3####################
layer{
		name:"Conv2d_106"
		type:"Convolution"
		bottom:"Conv2d_103"
		top:"Conv2d_106"
		convolution_param{
			num_output:16
			group:1
			kernel_size:3
			stride:1
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_107_BN"
		type:"BatchNorm"
		bottom:"Conv2d_106"
		top:"Conv2d_106"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_107_Scale"
		type:"Scale"
		bottom:"Conv2d_106"
		top:"Conv2d_106"
		scale_param{
			bias_term: true
		}
}

####################ssh1-concat####################
layer{
		name:"SSH1_Concat"
		type:"Concat"
		bottom:"Conv2d_96"
		bottom:"Conv2d_101"
		bottom:"Conv2d_106"
		top:"SSH1_Concat"
		concat_param{
			axis: 1
		}
}
layer{
		name:"SSH1_Concat_ReLU"
		type:"ReLU"
		bottom:"SSH1_Concat"
		top:"SSH1_Concat_ReLU"
}


####################ssh2-conv3X3####################
layer{
		name:"Conv2d_108"
		type:"Convolution"
		bottom:"Conv2d_93"
		top:"Conv2d_108"
		convolution_param{
			num_output:32
			group:1
			kernel_size:3
			stride:1
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_109_BN"
		type:"BatchNorm"
		bottom:"Conv2d_108"
		top:"Conv2d_108"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_109_Scale"
		type:"Scale"
		bottom:"Conv2d_108"
		top:"Conv2d_108"
		scale_param{
			bias_term: true
		}
}
####################ssh2-conv5X5_1####################
layer{
		name:"Conv2d_110"
		type:"Convolution"
		bottom:"Conv2d_93"
		top:"Conv2d_110"
		convolution_param{
			num_output:16
			group:1
			kernel_size:3
			stride:1
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_111_BN"
		type:"BatchNorm"
		bottom:"Conv2d_110"
		top:"Conv2d_110"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_111_Scale"
		type:"Scale"
		bottom:"Conv2d_110"
		top:"Conv2d_110"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_112"
		type:"ReLU"
		bottom:"Conv2d_110"
		top:"Conv2d_110"
		relu_param{
			negative_slope:0.1
		}
}
####################ssh2-conv5X5_2####################
layer{
		name:"Conv2d_113"
		type:"Convolution"
		bottom:"Conv2d_110"
		top:"Conv2d_113"
		convolution_param{
			num_output:16
			group:1
			kernel_size:3
			stride:1
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_114_BN"
		type:"BatchNorm"
		bottom:"Conv2d_113"
		top:"Conv2d_113"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_114_Scale"
		type:"Scale"
		bottom:"Conv2d_113"
		top:"Conv2d_113"
		scale_param{
			bias_term: true
		}
}
####################ssh2-conv7X7_2####################
layer{
		name:"Conv2d_115"
		type:"Convolution"
		bottom:"Conv2d_110"
		top:"Conv2d_115"
		convolution_param{
			num_output:16
			group:1
			kernel_size:3
			stride:1
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_116_BN"
		type:"BatchNorm"
		bottom:"Conv2d_115"
		top:"Conv2d_115"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_116_Scale"
		type:"Scale"
		bottom:"Conv2d_115"
		top:"Conv2d_115"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_117"
		type:"ReLU"
		bottom:"Conv2d_115"
		top:"Conv2d_115"
		relu_param{
			negative_slope:0.1
		}
}
####################ssh2-conv7x7_3####################
layer{
		name:"Conv2d_118"
		type:"Convolution"
		bottom:"Conv2d_115"
		top:"Conv2d_118"
		convolution_param{
			num_output:16
			group:1
			kernel_size:3
			stride:1
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_119_BN"
		type:"BatchNorm"
		bottom:"Conv2d_118"
		top:"Conv2d_118"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_119_Scale"
		type:"Scale"
		bottom:"Conv2d_118"
		top:"Conv2d_118"
		scale_param{
			bias_term: true
		}
}
####################ssh2-concat####################
layer{
		name:"SSH2_Concat"
		type:"Concat"
		bottom:"Conv2d_108"
		bottom:"Conv2d_113"
		bottom:"Conv2d_118"
		top:"SSH2_Concat"
		concat_param{
			axis: 1
		}
}
layer{
		name:"SSH2_Concat_ReLU"
		type:"ReLU"
		bottom:"SSH2_Concat"
		top:"SSH2_Concat_ReLU"
}

####################ssh3-conv3X3####################
layer{
		name:"Conv2d_120"
		type:"Convolution"
		bottom:"Conv2d_87"
		top:"Conv2d_120"
		convolution_param{
			num_output:32
			group:1
			kernel_size:3
			stride:1
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_121_BN"
		type:"BatchNorm"
		bottom:"Conv2d_120"
		top:"Conv2d_120"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_121_Scale"
		type:"Scale"
		bottom:"Conv2d_120"
		top:"Conv2d_120"
		scale_param{
			bias_term: true
		}
}
####################ssh3-conv5X5_1####################
layer{
		name:"Conv2d_122"
		type:"Convolution"
		bottom:"Conv2d_87"
		top:"Conv2d_122"
		convolution_param{
			num_output:16
			group:1
			kernel_size:3
			stride:1
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_123_BN"
		type:"BatchNorm"
		bottom:"Conv2d_122"
		top:"Conv2d_122"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_123_Scale"
		type:"Scale"
		bottom:"Conv2d_122"
		top:"Conv2d_122"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_124"
		type:"ReLU"
		bottom:"Conv2d_122"
		top:"Conv2d_122"
		relu_param{
			negative_slope:0.1
		}
}
####################ssh3-conv5X5_2####################
layer{
		name:"Conv2d_125"
		type:"Convolution"
		bottom:"Conv2d_122"
		top:"Conv2d_125"
		convolution_param{
			num_output:16
			group:1
			kernel_size:3
			stride:1
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_126_BN"
		type:"BatchNorm"
		bottom:"Conv2d_125"
		top:"Conv2d_125"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_126_Scale"
		type:"Scale"
		bottom:"Conv2d_125"
		top:"Conv2d_125"
		scale_param{
			bias_term: true
		}
}
####################ssh3-conv7X7_2####################
layer{
		name:"Conv2d_127"
		type:"Convolution"
		bottom:"Conv2d_122"
		top:"Conv2d_127"
		convolution_param{
			num_output:16
			group:1
			kernel_size:3
			stride:1
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_128_BN"
		type:"BatchNorm"
		bottom:"Conv2d_127"
		top:"Conv2d_127"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_128_Scale"
		type:"Scale"
		bottom:"Conv2d_127"
		top:"Conv2d_127"
		scale_param{
			bias_term: true
		}
}
layer{
		name:"LeakyReLU_129"
		type:"ReLU"
		bottom:"Conv2d_127"
		top:"Conv2d_127"
		relu_param{
			negative_slope:0.1
		}
}
####################ssh3-conv7X7_3####################
layer{
		name:"Conv2d_130"
		type:"Convolution"
		bottom:"Conv2d_127"
		top:"Conv2d_130"
		convolution_param{
			num_output:16
			group:1
			kernel_size:3
			stride:1
			pad:1
			bias_term: false
		}
}
layer{
		name:"BatchNorm2d_131_BN"
		type:"BatchNorm"
		bottom:"Conv2d_130"
		top:"Conv2d_130"
		batch_norm_param{
			use_global_stats: true
		}
}
layer{
		name:"BatchNorm2d_131_Scale"
		type:"Scale"
		bottom:"Conv2d_130"
		top:"Conv2d_130"
		scale_param{
			bias_term: true
		}
}
####################ssh3-concat####################
layer{
		name:"SSH3_Concat"
		type:"Concat"
		bottom:"Conv2d_120"
		bottom:"Conv2d_125"
		bottom:"Conv2d_130"
		top:"SSH3_Concat"
		concat_param{
			axis: 1
		}
}
layer{
		name:"SSH3_Concat_ReLU"
		type:"ReLU"
		bottom:"SSH3_Concat"
		top:"SSH3_Concat_ReLU"
}

####################ClassHead-0####################
layer{
		name:"Conv2d_132"
		type:"Convolution"
		bottom:"SSH1_Concat_ReLU"
		top:"Conv2d_132"
		convolution_param{
			num_output:4
			group:1
			kernel_size:1
			stride:1
			pad:0
			bias_term: true
		}
}
layer{
		name:"ClassHead_0_permute"
		type:"Permute"
		bottom:"Conv2d_132"
		top:"ClassHead_0_permute"
		permute_param {
			order: 0
			order: 2
			order: 3
			order: 1
		}
}
layer{
		name:"ClassHead_0_reshape"
		type:"Reshape"
		bottom:"ClassHead_0_permute"
		top:"ClassHead_0_reshape"
		reshape_param {
			shape {
				dim:0
				dim:-1
				dim:2				
			}
		}
}


####################ClassHead-1####################
layer{
		name:"Conv2d_133"
		type:"Convolution"
		bottom:"SSH2_Concat_ReLU"
		top:"Conv2d_133"
		convolution_param{
			num_output:4
			group:1
			kernel_size:1
			stride:1
			pad:0
			bias_term: true
		}
}
layer{
		name:"ClassHead_1_permute"
		type:"Permute"
		bottom:"Conv2d_133"
		top:"ClassHead_1_permute"
		permute_param {
			order: 0
			order: 2
			order: 3
			order: 1
		}
}
layer{
		name:"ClassHead_1_reshape"
		type:"Reshape"
		bottom:"ClassHead_1_permute"
		top:"ClassHead_1_reshape"
		reshape_param {
			shape {
				dim:0
				dim:-1
				dim:2				
			}
		}
}

####################ClassHead-2####################
layer{
		name:"Conv2d_134"
		type:"Convolution"
		bottom:"SSH3_Concat_ReLU"
		top:"Conv2d_134"
		convolution_param{
			num_output:4
			group:1
			kernel_size:1
			stride:1
			pad:0
			bias_term: true
		}
}
layer{
		name:"ClassHead_2_permute"
		type:"Permute"
		bottom:"Conv2d_134"
		top:"ClassHead_2_permute"
		permute_param {
			order: 0
			order: 2
			order: 3
			order: 1
		}
}
layer{
		name:"ClassHead_2_reshape"
		type:"Reshape"
		bottom:"ClassHead_2_permute"
		top:"ClassHead_2_reshape"
		reshape_param {
			shape {
				dim:0
				dim:-1
				dim:2				
			}
		}
}

####################ClassHead-concat####################
layer{
		name:"ClassHead_Concat"
		type:"Concat"
		bottom:"ClassHead_0_reshape"
		bottom:"ClassHead_1_reshape"
		bottom:"ClassHead_2_reshape"
		top:"ClassHead_Concat"
		concat_param{
			axis: 1
		}
}
layer{
		name:"ClassHead_Softmax"
		type:"Softmax"
		bottom:"ClassHead_Concat"
		top:"ClassHead_Softmax"
		softmax_param{
			axis: -1
		}
}

####################BboxHead-0####################
layer{
		name:"Conv2d_135"
		type:"Convolution"
		bottom:"SSH1_Concat_ReLU"
		top:"Conv2d_135"
		convolution_param{
			num_output:8
			group:1
			kernel_size:1
			stride:1
			pad:0
			bias_term: true
		}
}
layer{
		name:"BboxHead_0_permute"
		type:"Permute"
		bottom:"Conv2d_135"
		top:"BboxHead_0_permute"
		permute_param {
			order: 0
			order: 2
			order: 3
			order: 1
		}
}
layer{
		name:"BboxHead_0_reshape"
		type:"Reshape"
		bottom:"BboxHead_0_permute"
		top:"BboxHead_0_reshape"
		reshape_param {
			shape {
				dim:0
				dim:-1
				dim:4				
			}
		}
}

####################BboxHead-1####################
layer{
		name:"Conv2d_136"
		type:"Convolution"
		bottom:"SSH2_Concat_ReLU"
		top:"Conv2d_136"
		convolution_param{
			num_output:8
			group:1
			kernel_size:1
			stride:1
			pad:0
			bias_term: true
		}
}
layer{
		name:"BboxHead_1_permute"
		type:"Permute"
		bottom:"Conv2d_136"
		top:"BboxHead_1_permute"
		permute_param {
			order: 0
			order: 2
			order: 3
			order: 1
		}
}
layer{
		name:"BboxHead_1_reshape"
		type:"Reshape"
		bottom:"BboxHead_1_permute"
		top:"BboxHead_1_reshape"
		reshape_param {
			shape {
				dim:0
				dim:-1
				dim:4				
			}
		}
}
####################BboxHead-2####################
layer{
		name:"Conv2d_137"
		type:"Convolution"
		bottom:"SSH3_Concat_ReLU"
		top:"Conv2d_137"
		convolution_param{
			num_output:8
			group:1
			kernel_size:1
			stride:1
			pad:0
			bias_term: true
		}
}
layer{
		name:"BboxHead_2_permute"
		type:"Permute"
		bottom:"Conv2d_137"
		top:"BboxHead_2_permute"
		permute_param {
			order: 0
			order: 2
			order: 3
			order: 1
		}
}
layer{
		name:"BboxHead_2_reshape"
		type:"Reshape"
		bottom:"BboxHead_2_permute"
		top:"BboxHead_2_reshape"
		reshape_param {
			shape {
				dim:0
				dim:-1
				dim:4				
			}
		}
}
####################BboxHead-concat####################
layer{
		name:"BboxHead_Concat"
		type:"Concat"
		bottom:"BboxHead_0_reshape"
		bottom:"BboxHead_1_reshape"
		bottom:"BboxHead_2_reshape"
		top:"BboxHead_Concat"
		concat_param{
			axis: 1
		}
}

####################LandmarkHead-0####################
layer{
		name:"Conv2d_138"
		type:"Convolution"
		bottom:"SSH1_Concat_ReLU"
		top:"Conv2d_138"
		convolution_param{
			num_output:20
			group:1
			kernel_size:1
			stride:1
			pad:0
			bias_term: true
		}
}
layer{
		name:"LandmarkHead_0_permute"
		type:"Permute"
		bottom:"Conv2d_138"
		top:"LandmarkHead_0_permute"
		permute_param {
			order: 0
			order: 2
			order: 3
			order: 1
		}
}
layer{
		name:"LandmarkHead_0_reshape"
		type:"Reshape"
		bottom:"LandmarkHead_0_permute"
		top:"LandmarkHead_0_reshape"
		reshape_param {
			shape {
				dim:0
				dim:-1
				dim:10				
			}
		}
}
####################LandmarkHead-1####################
layer{
		name:"Conv2d_139"
		type:"Convolution"
		bottom:"SSH2_Concat_ReLU"
		top:"Conv2d_139"
		convolution_param{
			num_output:20
			group:1
			kernel_size:1
			stride:1
			pad:0
			bias_term: true
		}
}
layer{
		name:"LandmarkHead_1_permute"
		type:"Permute"
		bottom:"Conv2d_139"
		top:"LandmarkHead_1_permute"
		permute_param {
			order: 0
			order: 2
			order: 3
			order: 1
		}
}
layer{
		name:"LandmarkHead_1_reshape"
		type:"Reshape"
		bottom:"LandmarkHead_1_permute"
		top:"LandmarkHead_1_reshape"
		reshape_param {
			shape {
				dim:0
				dim:-1
				dim:10				
			}
		}
}
####################LandmarkHead-2####################
layer{
		name:"Conv2d_140"
		type:"Convolution"
		bottom:"SSH3_Concat_ReLU"
		top:"Conv2d_140"
		convolution_param{
			num_output:20
			group:1
			kernel_size:1
			stride:1
			pad:0
			bias_term: true
		}
}
layer{
		name:"LandmarkHead_2_permute"
		type:"Permute"
		bottom:"Conv2d_140"
		top:"LandmarkHead_2_permute"
		permute_param {
			order: 0
			order: 2
			order: 3
			order: 1
		}
}
layer{
		name:"LandmarkHead_2_reshape"
		type:"Reshape"
		bottom:"LandmarkHead_2_permute"
		top:"LandmarkHead_2_reshape"
		reshape_param {
			shape {
				dim:0
				dim:-1
				dim:10				
			}
		}
}
####################LandmarkHead-concat####################
layer{
		name:"LandmarkHead_Concat"
		type:"Concat"
		bottom:"LandmarkHead_0_reshape"
		bottom:"LandmarkHead_1_reshape"
		bottom:"LandmarkHead_2_reshape"
		top:"LandmarkHead_Concat"
		concat_param{
			axis: 1
		}
}
